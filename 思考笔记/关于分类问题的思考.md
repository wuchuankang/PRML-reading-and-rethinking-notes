## 关于分类问题的思考

分类问题有判别函数、概率生成模型、概率判别模型、贝叶斯模型。

+ 概率生成模型

  给定新的输入$\bold x​$，要预测$p(C_1/\bold x)​$，概率生成模型的意思就是通过把生成数据的概率分布$p(y,\bold x)​$求出来，然后根据贝叶斯定理就可以求出来了。

  对于二分问题，
  $$
  p(C_1|\bold x)=\frac {p(C_1,\bold x)}{p(\bold x)}=\frac {p(\bold x|C_1)p(C_1)}{\sum_{k=1}^2 p(\bold x|C_k)p(C_k)} \tag 1
  $$
  但是这里有个难点就是求$p(\bold x|C_k)​$，比如，假设$\bold x​$是连续函数，$p(\bold x|C_k)​$服从某一分布，比如是高斯分布，$p(\bold x|C_k)\sim \mathcal N(\bold x|\boldsymbol \mu_k,\boldsymbol \Sigma)​$，我们通过最大似然估计出了$\boldsymbol \mu_k,\boldsymbol \Sigma​$，但是当我们要求$p(C_k|\bold x)​$时，需要求$p(\bold x|C_k)​$，假设$\bold x​$是$m​$维变量，即求：
  $$
  p(\bold x|C_k)=\int_{-\infty}^{x_1}...\int_{-\infty}^{x_m}\mathcal N(\bold x|\boldsymbol \mu_k,\boldsymbol \Sigma)dx_1...dx_m  \tag2
  $$
  这个积分是很难求的，即使换成其他分布，同样积分也是难求的。那么我们需要走另外的路，该怎么解决呢？

  方案是：

  假如$p(C_1/\bold x)​$还可以表示成某一函数，而这个函数的参数又可以用概率模型中的参数来表示，例如，如果概率模型是是高斯分布，那么函数的参数可以用高斯模型的参数$\boldsymbol \mu_k,\boldsymbol \Sigma​$来表示，那么就可以不用积分就求出来了$p(C_1/\bold x)​$，因为只要把新的输入带入到函数中就可以了。

  那么问题转化为如何找这个函数，幸运的是，对于分类问题，天然就有这种函数，对于二分类：sigmoid函数，多分类：softmax函数。

  下面说明推导一下为什么天然具备，其实来源于贝叶斯定理，假如是二分问题：
  $$
  p(C_1|\bold x)=\frac {p(\bold x|C_1)p(C_1)}{\sum_{k=1}^2 p(\bold x|C_k)p(C_k)}=\frac {1}{1+\frac{p(\bold x|C_2)p(C_2)}{p(\bold x|C_1)p(C_1)}}=\frac {1}{1+\exp(-\ln\frac{p(\bold x|C_1)p(C_1)}{p(\bold x|C_2)p(C_2)})}=\frac {1}{1+\exp(-a)}=\sigma(a)  \tag3
  $$
  其中：
  $$
  a=\ln\frac{p(\bold x|C_1)p(C_1)}{p(\bold x|C_2)p(C_2)}  \tag 4
  $$
  $\sigma(a)$就是$sigmoid$函数，如果我们让$a=w^T \bold x$，那么线性模型就建立起来了，也就是：
  $$
  p(C_1|\bold x)=\sigma(w^T\bold x) \tag 5
  $$
  而
  $$
  p(C_2|\bold x)=1-p(C_1|\bold x) \tag {5.1}
  $$
  这里要说明一下，既然找到了$p(C_1/\bold x)$的函数形式，那么直接用最大似然函数就可以把函数的参数求出来了，其实这就是概率判别模型，那这么说，似乎没必要用上面间接求法。其实当然有不同，因为优化的函数不同，概率生成模型一方面更具有解释性，另一方面，如果概率类型选择合适，效果会更好。

+ 输入特征连续问题：高斯生成模型

  1. 先考虑二分问题，当输入特征$\bold x$是连续变量时，假设$p(\bold x|C_k)\sim \mathcal N(\bold x|\boldsymbol \mu_k,\boldsymbol \Sigma)$，对与$C_1$和$C_2$，高斯分布使用相同的$\Sigma$，由$(4)$可以得出：